# Efficient-LLMAgent-Survey
This repository maintains a curated list of papers related to Large Language Model Based Agents (LLM Agents), especially focusing on efficient serving methods for LLM Agents.

This paper list covers several main aspects of efficient serving methods for LLM Agents. 
Table of content:

- [Efficient-LLMAgent-Survey](#efficient-llmagent-survey)
  - [What is LLM Agent](#what-is-llm-agent)
  - [Efficient Serving LLM Agent](#efficient-serving-llm-agent)
    - [LLM Serving](#llm-serving)
    - [Planning](#planning)
    - [Tool and Action](#tool-and-action)
      - [Serverless](#serverless)
    - [Memory](#memory)
    - [Agent Framework](#agent-framework)
  - [Component Collaboration](#component-collaboration)
  - [Device-Edge-Cloud Collaboration](#device-edge-cloud-collaboration)
  - [LLM and LLM Agent Framework](#llm-and-llm-agent-framework)
  - [Benchmark, Trace, and Dataset](#benchmark-trace-and-dataset)
  - [LLM and Agent on Mobile Platform](#llm-and-agent-on-mobile-platform)
  - [Survey Papers](#survey-papers)
  - [Others](#others)



## What is LLM Agent
- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)

## Efficient Serving LLM Agent

### LLM Serving
- [HeteGen](https://arxiv.org/abs/2403.01164) HeteGen: Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices | MLSys'24

- [POLCA](https://www.microsoft.com/en-us/research/uploads/prodnew/2024/03/GPU_Power_ASPLOS_24.pdf)Characterizing Power Management Opportunities for LLMs in the Cloud | ASPLOS'24

### Planning

- [An LLM Compiler for Parallel Function Calling](https://arxiv.org/abs/2312.04511)
- [Dynamic Planning with a LLM](https://arxiv.org/abs/2308.06391)
### Tool and Action
- [ToolChain^*](https://arxiv.org/abs/2310.13227)ToolChain^*: Efficient Action Space Navigation in Large Language Models with A* Search | ICLR'24
- [Middleware for LLMs: Tools Are Instrumental for Language Agents in Complex Environments](https://arxiv.org/abs/2402.14672)

- [ToolNet](https://arxiv.org/abs/2403.00839) ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph

#### Serverless
- [Serverless LLM](https://arxiv.org/abs/2401.14351) ServerlessLLM: Locality-Enhanced Serverless Inference for Large Language Models | OSDI'24
  
### Memory

### Agent Framework

## Component Collaboration

Multi-Agent

## Device-Edge-Cloud Collaboration
- [Hybrid LLM](https://openreview.net/forum?id=02f3mUtqnM) Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing | ICLR'24

- [Caching](https://arxiv.org/abs/2306.02003) On Optimal Caching and Model Multiplexing for Large Model Inference | NeurIPS'23

- [Octopus v2](https://arxiv.org/abs/2404.01744v5)Octopus v2: On-device language model for super agent | Stanford 
- 
## LLM and LLM Agent Framework


## Benchmark, Trace, and Dataset
- [BurstGPT](https://arxiv.org/abs/2401.17644)Towards Efficient and Reliable LLM Serving: A Real-World Workload Study

## LLM and Agent on Mobile Platform

- [Mobile LLM](https://arxiv.org/abs/2402.14905) MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases | Meta



## Survey Papers
- [A Survey on Effective Invocation Methods of Massive LLM Services](https://arxiv.org/abs/2402.03408)

## Others

